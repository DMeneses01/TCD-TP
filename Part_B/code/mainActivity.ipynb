{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Parte B: Classificação de Atividades Humanas \n",
    "### Tópicos de Ciência dos Dados - MECD (2022/2023)\n",
    "\n",
    "### Autores\n",
    "\n",
    "- Duarte Meneses - 2019216949\n",
    "- Patricia Costa - 2019213995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_labels = [ 'Device ID', 'accelerometer x', 'accelerometer y', 'accelerometer z',\n",
    "    'gyroscope x', 'gyroscope y', 'gyroscope z', 'magnetometer x', 'magnetometer y', 'magnetometer z',\n",
    "    'Timestamp', 'Activity Label']\n",
    "\n",
    "activities = np.array(['Stand', 'Sit', 'Sit and Talk', 'Walk', 'Walk and Talk', 'Climb Stair (up/down)',\n",
    "    'Climb Stair (up/down) and talk', 'Stand -> Sit', 'Sit -> Stand', 'Stand -> Sit and talk', 'Sit -> Stand and talk',\n",
    "    'Stand -> walk', 'Walk -> stand', 'Stand -> climb stairs (up/down)(and talk)', 'Climb stairs (up/down) -> walk',\n",
    "    'Climb stairs (up/down) and talk -> walk and talk'])\n",
    "\n",
    "sensors = ['Acc', 'Gyr', 'Mag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 e 4.6 da Parte A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = iris.data[:, :2]  # we only take the first two features.\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Train-Test (TT) e Train-Validation-Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "def train_test(datav, targetv, train_size, shuffle = False):\n",
    "    trainTest = []\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(datav, targetv, train_size=train_size, shuffle=shuffle)\n",
    "\n",
    "    trainTest.append({\"TRAIN\": [x_train, y_train], \"TEST\": [x_test, y_test]})\n",
    "\n",
    "    return trainTest\n",
    "\n",
    "def train_validation_test(data, target, train_size, validation_size, shuffle = False):\n",
    "    trainValidation = []\n",
    "\n",
    "    x_train, x_rem, y_train, y_rem = train_test_split(data, target, train_size=train_size, shuffle=shuffle)\n",
    "\n",
    "    test_size = 1 - train_size - validation_size\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(x_rem, y_rem, test_size = test_size, shuffle=shuffle)\n",
    "\n",
    "    trainValidation.append({\"TRAIN\": [x_train, y_train], \"TEST\": [x_test, y_test], \"Validation\": [x_valid, y_valid]})\n",
    "    \n",
    "    return trainValidation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. K-fold data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "\n",
    "def k_fold(x, y, n_splits, shuffle = False, random_state = None):\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "    kfold = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        print(\"TRAIN:\", [x_train, y_train])\n",
    "        print(\"TEST:\", [x_test, y_test])\n",
    "        kfold.append({\"TRAIN\": [x_train, y_train], \"TEST\": [x_test, y_test]})\n",
    "    \n",
    "    return kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train Test--\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TRAIN': [array([[1, 2],\n",
       "          [3, 4]]),\n",
       "   array([1, 2])],\n",
       "  'TEST': [array([[1, 2],\n",
       "          [3, 4]]),\n",
       "   array([3, 4])]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--Train Validation Test--\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TRAIN': [array([[1, 2]]), array([1])],\n",
       "  'TEST': [array([[3, 4]]), array([4])],\n",
       "  'Validation': [array([[3, 4],\n",
       "          [1, 2]]),\n",
       "   array([2, 3])]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--K Fold--\n",
      "\n",
      "TRAIN: [array([[3, 4],\n",
      "       [1, 2],\n",
      "       [3, 4]]), array([2, 3, 4])]\n",
      "TEST: [array([[1, 2]]), array([1])]\n",
      "TRAIN: [array([[1, 2],\n",
      "       [1, 2],\n",
      "       [3, 4]]), array([1, 3, 4])]\n",
      "TEST: [array([[3, 4]]), array([2])]\n",
      "TRAIN: [array([[1, 2],\n",
      "       [3, 4],\n",
      "       [3, 4]]), array([1, 2, 4])]\n",
      "TEST: [array([[1, 2]]), array([3])]\n",
      "TRAIN: [array([[1, 2],\n",
      "       [3, 4],\n",
      "       [1, 2]]), array([1, 2, 3])]\n",
      "TEST: [array([[3, 4]]), array([4])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TRAIN': [array([[3, 4],\n",
       "          [1, 2],\n",
       "          [3, 4]]),\n",
       "   array([2, 3, 4])],\n",
       "  'TEST': [array([[1, 2]]), array([1])]},\n",
       " {'TRAIN': [array([[1, 2],\n",
       "          [1, 2],\n",
       "          [3, 4]]),\n",
       "   array([1, 3, 4])],\n",
       "  'TEST': [array([[3, 4]]), array([2])]},\n",
       " {'TRAIN': [array([[1, 2],\n",
       "          [3, 4],\n",
       "          [3, 4]]),\n",
       "   array([1, 2, 4])],\n",
       "  'TEST': [array([[1, 2]]), array([3])]},\n",
       " {'TRAIN': [array([[1, 2],\n",
       "          [3, 4],\n",
       "          [1, 2]]),\n",
       "   array([1, 2, 3])],\n",
       "  'TEST': [array([[3, 4]]), array([4])]}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testes\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "print(\"--Train Test--\\n\")\n",
    "trainTest = train_test(X, y, 0.7)\n",
    "display(trainTest)\n",
    "\n",
    "print(\"\\n--Train Validation Test--\\n\")\n",
    "trainValidation = train_validation_test(X, y, 0.4, 0.3)\n",
    "display(trainValidation)\n",
    "\n",
    "print(\"\\n--K Fold--\\n\")\n",
    "kFold = k_fold(X, y, 4)\n",
    "display(kFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Métricas de exactidação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste\n",
    "true = [2, 0, 2, 2, 0, 1]\n",
    "pred = [0, 0, 2, 2, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Explicação do parâmetro average\n",
    "\n",
    "**'binary'**:\n",
    "Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n",
    "\n",
    "**'micro'**:\n",
    "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "**'macro'**:\n",
    "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "**'weighted'**:\n",
    "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "**'samples'**:\n",
    "Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2 0 0]\n",
      " [0 0 1]\n",
      " [1 0 2]]\n",
      "\n",
      "Recall:  0.6666666666666666\n",
      "\n",
      "Precision:  0.5555555555555555\n",
      "\n",
      "F1-score:  0.6\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d5ba5\">\n",
       "  <caption>Confusion Matrix</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d5ba5_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_d5ba5_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_d5ba5_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d5ba5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d5ba5_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_d5ba5_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_d5ba5_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5ba5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d5ba5_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_d5ba5_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_d5ba5_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5ba5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d5ba5_row2_col0\" class=\"data row2 col0\" >1</td>\n",
       "      <td id=\"T_d5ba5_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_d5ba5_row2_col2\" class=\"data row2 col2\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22d9cc900d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metrics\n",
       "Recall     0.666667\n",
       "Precision  0.555556\n",
       "F1-score   0.600000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "\n",
    "def metrics(true, pred):\n",
    "    cm = confusion_matrix(true, pred)\n",
    "    rs = recall_score(true, pred, average='weighted', zero_division=0)\n",
    "    ps = precision_score(true, pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true, pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print('Confusion Matrix:\\n', cm)\n",
    "    print('\\nRecall: ', rs)\n",
    "    print('\\nPrecision: ', ps)\n",
    "    print('\\nF1-score: ', f1)\n",
    "    print('-'*50)\n",
    "\n",
    "    return [cm, rs, ps, f1]\n",
    "\n",
    "def visualize(cm, rs, ps, f1):\n",
    "    cmFrame = pd.DataFrame(cm).style.set_caption(\"Confusion Matrix\")\n",
    "    display(cmFrame)\n",
    "    metricsFrame = pd.DataFrame([rs, ps, f1], columns=['Metrics']).rename(index={0: 'Recall', 1: 'Precision', 2: 'F1-score'})\n",
    "    display(metricsFrame)\n",
    "    \n",
    "\n",
    "cm, rs, ps, f1 = metrics(true, pred)\n",
    "visualize(cm, rs, ps, f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e1b8a2c375dc7eddb7fcbc77a4789e02579d6e777ba36c235362aa19e94720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
